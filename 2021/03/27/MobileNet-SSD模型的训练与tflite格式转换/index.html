<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="MobileNet-SSD模型的训练与tflite格式转换"><meta name="keywords" content="CNN,MobileNet-SSD,tensorflow lite"><meta name="author" content="gzwang"><meta name="copyright" content="gzwang"><title>MobileNet-SSD模型的训练与tflite格式转换 | Rubina の blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.9.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.9.0"><meta name="format-detection" content="telephone=no"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  hexoVersion: '5.4.0'
} </script><meta name="generator" content="Hexo 5.4.0"></head><body><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar" data-display="true"><div class="toggle-sidebar-info text-center"><span data-toggle="切换文章详情">切换站点概览</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD"><span class="toc-number">1.</span> <span class="toc-text">下载</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="toc-number">2.</span> <span class="toc-text">环境搭建</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BE%E7%BD%AE-PYTHONPATH"><span class="toc-number">2.1.</span> <span class="toc-text">设置 PYTHONPATH</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-protobuf"><span class="toc-number">2.2.</span> <span class="toc-text">安装 protobuf</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85-API"><span class="toc-number">2.3.</span> <span class="toc-text">安装 API</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E5%92%8C%E8%AE%AD%E7%BB%83"><span class="toc-number">3.</span> <span class="toc-text">配置和训练</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B"><span class="toc-number">4.</span> <span class="toc-text">测试模型</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TFLite-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2"><span class="toc-number">5.</span> <span class="toc-text">TFLite 模型转换</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C"><span class="toc-number">5.1.</span> <span class="toc-text">准备工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E8%BD%AC%E6%8D%A2"><span class="toc-number">5.2.</span> <span class="toc-text">开始转换</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">6.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://gzwangu.github.io/img/avatar.jpg"></div><div class="author-info__name text-center">gzwang</div><div class="author-info__description text-center">Study and Life growth record</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">文章</span><span class="pull-right">33</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">标签</span><span class="pull-right">37</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">分类</span><span class="pull-right">10</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://crownz.run/">crownZ</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://blog.zyuanlee.cn/">Pandalzy</a><a class="author-info-links__name text-center" target="_blank" rel="noopener" href="https://blog.zguolee.cn/">Lee</a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">Rubina の blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus">   <a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span><span class="pull-right"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> 搜索</span></a></span></div><div id="post-info"><div id="post-title">MobileNet-SSD模型的训练与tflite格式转换</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2021-03-27</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><div class="post-meta-wordcount"><span>字数总计: </span><span class="word-count">2.6k</span><span class="post-meta__separator">|</span><span>阅读时长: 11 分钟</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><p>最近在做毕业设计嵌入式端的目标检测系统，看了前人写的论文大多数用的都是 MobileNet-SSD 模型，就去学习了一下。MobileNet v1 是 Google 2017年发表的用于移动和嵌入式视觉应用程序的高效模型，其核心思想就是提出了深度可分离卷积（Depthwise Separable Convolution）来代替标准卷积，同时引入两个全局超参数（宽度和分辨率）进一步缩小模型规模来构建更小、更快的移动网络。其后 v2 v3 版本（还没学）都是在 v1 基础上引入新技术不断缩小模型。</p>
<p>在树莓派 4B（Raspberry Pi OS、4GB、tensorflow 1.4）直接调用 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md">TensorFlow object detection API</a> 中的 ssd_mobilenet_v2_coco 预训练模型卡的起飞，大概只有0.8-0.9 FPS，毫无目标检测体验。想着把模型在 VOC2012 数据集上再次训练，下面是 MobileNet-SSD 模型训练过程。</p>
<h1 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h1><ol>
<li>Github 下载/克隆 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models">tensorflow-models</a>，后面的操作都要在这个目录下执行，建议创建 Python 虚拟环境</li>
<li>下载数据集 <a target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar">VOC2012</a>，也可以使用 <a target="_blank" rel="noopener" href="https://github.com/tzutalin/labelImg">LabelImg</a> 制作数据集训练自己的数据</li>
<li>下载 MobileNet-SSD 预训练模型，这里我下载的是 <a target="_blank" rel="noopener" href="http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2018_01_28.tar.gz">ssd_mobilenet_v1_coco</a></li>
</ol>
<h1 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h1><table>
<thead>
<tr>
<th>基本配置</th>
<th>版本</th>
</tr>
</thead>
<tbody><tr>
<td>CPU</td>
<td>Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz   2.90 GHz</td>
</tr>
<tr>
<td>GPU</td>
<td>AMD Radeon(TM) 530 (没用)</td>
</tr>
<tr>
<td>RAM</td>
<td>12 GB</td>
</tr>
<tr>
<td>OS</td>
<td>Windows 10</td>
</tr>
<tr>
<td>Python</td>
<td>3.7.9</td>
</tr>
<tr>
<td>TensorFlow</td>
<td>1.15.5</td>
</tr>
</tbody></table>
<h2 id="设置-PYTHONPATH"><a href="#设置-PYTHONPATH" class="headerlink" title="设置 PYTHONPATH"></a>设置 PYTHONPATH</h2><p>需要修改 PYTHONPATH 环境变量以指向刚下载的 tensorflow-models 内的某些目录，这里我把文件重命名为 <code>models</code>。</p>
<table>
<thead>
<tr>
<th>变量名</th>
<th>变量值（根据自己的路径修改）</th>
</tr>
</thead>
<tbody><tr>
<td>PYTHONPATH</td>
<td>path\to\models;path\to\models\research\slim;</td>
</tr>
</tbody></table>
<p><img src="PYTHONPATH.png"></p>
<h2 id="安装-protobuf"><a href="#安装-protobuf" class="headerlink" title="安装 protobuf"></a>安装 protobuf</h2><p>这是一个轻便高效的序列化数据结构的协议，可以用于网络通信和数据存储的工具库（类似Json），但相比于Json，Protobuf 有更高的转化效率。Windows 下的安装很简单，只需到 github 上下载 <a target="_blank" rel="noopener" href="https://github.com/protocolbuffers/protobuf/releases">protobuf</a> 对应版本压缩包安装即可，如 protoc-3.15.6-win64.zip。</p>
<p>现在，使用 protoc 来编译目标检测 API 使用的协议 proto 文件来产生 py 文件。proto 文件放在 <code>models\research\object_detection\protos\</code> 中，从 <code>research/</code> 目录执行命令。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd models/research/</span></span><br><span class="line">protoc object_detection/protos/*.proto --python_out=.</span><br></pre></td></tr></table></figure>

<p>这时 protos 文件夹下会生成相应的 py 文件。</p>
<h2 id="安装-API"><a href="#安装-API" class="headerlink" title="安装 API"></a>安装 API</h2><p>继续在<code>research/</code>目录下执行：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python setup.py build</span><br><span class="line">python setup.py install</span><br><span class="line">python object_detection/builders/model_builder_test.py  <span class="comment"># 测试是否安装成功</span></span><br></pre></td></tr></table></figure>

<h1 id="配置和训练"><a href="#配置和训练" class="headerlink" title="配置和训练"></a>配置和训练</h1><p>在<code>object_detection/</code>目录下创建目录<code>ssd_model</code>，把下载好的 VOC2012 数据集解压进去，数据集路径为 <code>models\research\object_detection\ssd_model\VOCdevkit\</code>。执行以下命令将 VOC 数据集转换成 tfrecord 格式的数据。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">python ./object_detection/dataset_tools/create_pascal_tf_record.py --label_map_path=object_detection/data/pascal_label_map.pbtxt --data_dir=object_detection/ssd_model/VOCdevkit/ --year=VOC2012 --<span class="built_in">set</span>=train --output_path=object_detection/ssd_model/pascal_train.record </span><br><span class="line">python ./object_detection/dataset_tools/create_pascal_tf_record.py --label_map_path=object_detection/data/pascal_label_map.pbtxt --data_dir=object_detection/ssd_model/VOCdevkit/ --year=VOC2012 --<span class="built_in">set</span>=val --output_path=object_detection/ssd_model/pascal_val.record</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>然后会在<code>ssd_model/</code>目录下生成<code>pascal_train.record</code>和<code>pascal_val.record</code>两个文件，分别有650M左右。</p>
<p><img src="pascal_train_val.png"></p>
<p>复制 <code>object_detection\data\pascal_label_map.pbtxt</code> 和<code>object_detection\samples\configs\ssd_mobilenet_v1_coco.config</code>到 <code>ssd_model/</code> 目录下，接着把之前下载的<code>ssd_mobilenet_v1_coco</code>解压到<code>ssd_model/ssd_mobilenet</code>下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp object_detection/data/pascal_label_map.pbtxt object_detection/ssd_model/ </span><br><span class="line">cp object_detection/samples/configs/ssd_mobilenet_v1_coco.config object_detection/ssd_model/</span><br></pre></td></tr></table></figure>

<p>此时 <code>ssd_model</code> 下应有以下文件：</p>
<p><img src="ssd_model.png"></p>
<p>打开 pascal_label_map.pbtxt，这个文件里面是类似 Json 格式的 label 集，列出了数据集里有哪些<code>label</code>。Pascal VOC 这个数据集<code>label</code>共有20个。然后打开配置文件 <code>ssd_mobilenet_v1_coco.config</code>，把<code>num_classes</code>改为<code>20</code><br>配置默认训练次数<code>num_steps: 200000</code>，根据自己需要改，注意这个训练是很慢的，差不多以天为单位，所以可以适当改小点。</p>
<p>然后根据自己文件路径修改一些文件路径：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 预训练模型 ckpt 文件的位置</span><br><span class="line">fine_tune_checkpoint: &quot;D:/Code/Python/tfmodels/models/research/object_detection/ssd_model/ssd_mobilenet/model.ckpt&quot;</span><br><span class="line"></span><br><span class="line"># 训练数据位置以及标签文件位置</span><br><span class="line">train_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;D:/Code/Python/tfmodels/models/research/object_detection/ssd_model/pascal_train.record&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;D:/Code/Python/tfmodels/models/research/object_detection/ssd_model/pascal_label_map.pbtxt&quot;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># 测试数据位置和相应标签文件位置，shuffle表示是否随机选取测试图片</span><br><span class="line">eval_input_reader: &#123;</span><br><span class="line">  tf_record_input_reader &#123;</span><br><span class="line">    input_path: &quot;D:/Code/Python/tfmodels/models/research/object_detection/ssd_model/pascal_val.record&quot;</span><br><span class="line">  &#125;</span><br><span class="line">  label_map_path: &quot;D:/Code/Python/tfmodels/models/research/object_detection/ssd_model/pascal_label_map.pbtxt&quot;</span><br><span class="line">  shuffle: false</span><br><span class="line">  num_readers: 1</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 <code>object_detection\</code> 下新建文件夹 <code>train</code> 保存训练数据。完成之后，我们就可以训练了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd models/research/</span></span><br><span class="line">python object_detection/model_main.py \</span><br><span class="line">--pipeline_config_path=object_detection/ssd_model/ssd_mobilenet_v1_coco.config \</span><br><span class="line">--model_dir=object_detection/train \</span><br><span class="line">--alsologtostderr</span><br><span class="line"><span class="comment"># pipeline_config_path 为修改后的config文件的位置</span></span><br><span class="line"><span class="comment"># train_dir 为训练产生数据的保存位置</span></span><br></pre></td></tr></table></figure>



<p>训练可视化可以在 tensorboard 中查看训练情况，在浏览器中打开 <a target="_blank" rel="noopener" href="http://localhost:6006/">http://localhost:6006/</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=path/to/object_detection/train  <span class="comment"># 保存训练数据文件夹</span></span><br></pre></td></tr></table></figure>

<p><img src="tensorboard.png"></p>
<p>经过漫长的等待，在<code>/object_detection/train</code>目录下生成了训练好的模型。（下图未训练完）</p>
<p><img src="train.png"></p>
<p>创建文件夹<code>ssd_model/model</code>导出训练好的模型，生成 pb 文件，再把 pascal_label_map.pbtxt 的内容改成<code>txt</code>作为 labe l文件，这个模型就可以使用了。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">python object_detection/export_inference_graph.py \</span><br><span class="line">--input_type image_tensor \</span><br><span class="line">--pipeline_config_path object_detection/ssd_model/ssd_mobilenet_v1_coco.config \</span><br><span class="line">--trained_checkpoint_prefix object_detection/train/model.ckpt-77 \</span><br><span class="line">--output_directory object_detection/ssd_model/model/</span><br></pre></td></tr></table></figure>

<h1 id="测试模型"><a href="#测试模型" class="headerlink" title="测试模型"></a>测试模型</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> six.moves.urllib <span class="keyword">as</span> urllib</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> zipfile</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"><span class="keyword">from</span> distutils.version <span class="keyword">import</span> StrictVersion</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># This is needed since the notebook is stored in the object_detection folder.</span></span><br><span class="line">sys.path.append(<span class="string">&quot;..&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> StrictVersion(tf.__version__) &lt; StrictVersion(<span class="string">&#x27;1.9.0&#x27;</span>):</span><br><span class="line">    <span class="keyword">raise</span> ImportError(<span class="string">&#x27;Please upgrade your TensorFlow installation to v1.9.* or later!&#x27;</span>)</span><br><span class="line"></span><br><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">CWD_PATH = os.getcwd()</span><br><span class="line">PATH_TO_CKPT = os.path.join(CWD_PATH, <span class="string">&#x27;model&#x27;</span>, <span class="string">&#x27;frozen_inference_graph.pb&#x27;</span>)</span><br><span class="line"><span class="comment"># List of the strings that is used to add correct label for each box.</span></span><br><span class="line">PATH_TO_LABELS = os.path.join(CWD_PATH, <span class="string">&#x27;pascal_label_map.pbtxt&#x27;</span>)</span><br><span class="line"></span><br><span class="line">NUM_CLASSES = <span class="number">100</span></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">detection_graph = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    od_graph_def = tf.compat.v1.GraphDef()</span><br><span class="line">    <span class="keyword">with</span> tf.io.gfile.GFile(PATH_TO_CKPT, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> fid:</span><br><span class="line">        serialized_graph = fid.read()</span><br><span class="line">        od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">        tf.import_graph_def(od_graph_def, name=<span class="string">&#x27;&#x27;</span>)</span><br><span class="line">label_map = label_map_util.load_labelmap(PATH_TO_LABELS)</span><br><span class="line">categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=<span class="literal">True</span>)</span><br><span class="line">category_index = label_map_util.create_category_index(categories)</span><br><span class="line"><span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">    <span class="keyword">with</span> tf.compat.v1.Session(graph=detection_graph) <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            ret, image_np = cap.read()</span><br><span class="line">            <span class="comment"># Expand dimensions since the model expects images to have shape: [1, None, None, 3]</span></span><br><span class="line">            image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">            image_tensor = detection_graph.get_tensor_by_name(<span class="string">&#x27;image_tensor:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Each box represents a part of the image where a particular object was detected.</span></span><br><span class="line">            boxes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_boxes:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Each score represent how level of confidence for each of the objects.</span></span><br><span class="line">            <span class="comment"># Score is shown on the result image, together with the class label.</span></span><br><span class="line">            scores = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_scores:0&#x27;</span>)</span><br><span class="line">            classes = detection_graph.get_tensor_by_name(<span class="string">&#x27;detection_classes:0&#x27;</span>)</span><br><span class="line">            num_detections = detection_graph.get_tensor_by_name(<span class="string">&#x27;num_detections:0&#x27;</span>)</span><br><span class="line">            <span class="comment"># Actual detection.</span></span><br><span class="line">            (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">                [boxes, scores, classes, num_detections],</span><br><span class="line">                feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">            <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">            image = image_np</span><br><span class="line">            vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">                image_np, np.squeeze(boxes),</span><br><span class="line">                np.squeeze(classes).astype(np.int32),</span><br><span class="line">                np.squeeze(scores), category_index,</span><br><span class="line">                use_normalized_coordinates=<span class="literal">True</span>,</span><br><span class="line">                line_thickness=<span class="number">2</span>)</span><br><span class="line">            final_score = np.squeeze(scores)</span><br><span class="line">            count = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> scores <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">or</span> final_score[i] &gt; <span class="number">0.5</span>:</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;the count of objects is: &quot;</span>, count)</span><br><span class="line">            im_shape = image.shape</span><br><span class="line">            im_width = im_shape[<span class="number">1</span>]</span><br><span class="line">            im_height = im_shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> count != <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(count):</span><br><span class="line">                    <span class="comment"># print(boxes[0][i])</span></span><br><span class="line">                    y_min = boxes[<span class="number">0</span>][i][<span class="number">0</span>] * im_height</span><br><span class="line">                    x_min = boxes[<span class="number">0</span>][i][<span class="number">1</span>] * im_width</span><br><span class="line">                    y_max = boxes[<span class="number">0</span>][i][<span class="number">2</span>] * im_height</span><br><span class="line">                    x_max = boxes[<span class="number">0</span>][i][<span class="number">3</span>] * im_width</span><br><span class="line">                    cv2.rectangle(image, (<span class="built_in">int</span>(x_min), <span class="built_in">int</span>(y_min)), (<span class="built_in">int</span>(x_max), <span class="built_in">int</span>(y_max)), (<span class="number">0</span>, <span class="number">255</span>, <span class="number">255</span>), <span class="number">2</span>)</span><br><span class="line">                    <span class="comment">#print(&quot;object&#123;0&#125;: &#123;1&#125;&quot;.format(i, category_index[classes[0][i]][&#x27;name&#x27;]), &#x27;,Center_X:&#x27;, int((x_min + x_max) / 2), &#x27;,Center_Y:&#x27;, int((y_min + y_max) / 2))</span></span><br><span class="line">            <span class="comment"># print(x_min,y_min,x_max,y_max)</span></span><br><span class="line"></span><br><span class="line">            seconds = time.time() - start</span><br><span class="line">            start = time.time()</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Time taken : &#123;0&#125; seconds&quot;</span>.<span class="built_in">format</span>(seconds))</span><br><span class="line">            cv2.imshow(<span class="string">&#x27;object detection&#x27;</span>, cv2.resize(image, (<span class="number">800</span>, <span class="number">600</span>))) <span class="comment"># cv2.resize(image_np, (800,600))</span></span><br><span class="line">            <span class="keyword">if</span> cv2.waitKey(<span class="number">25</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">                cv2.destroyAllWindows()</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>

<h1 id="TFLite-模型转换"><a href="#TFLite-模型转换" class="headerlink" title="TFLite 模型转换"></a>TFLite 模型转换</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/guide?hl=zh-cn">TensorFlow Lite</a> 是一组工具，可帮助开发者在移动设备、嵌入式设备和 IoT 设备上运行 TensorFlow 模型。包括两个主要组件：TensorFlow Lite 解释器和 TensorFlow Lite 转换器。</p>
<p>解释器可以在手机、嵌入式 Linux 设备和微控制器等很多不同类型的硬件上运行经过专门优化的模型（.tflite），转换器可将 TensorFlow 模型转换为方便解释器使用的格式，并可引入优化以减小二进制文件的大小和提高性能。下面详细讲下转换过程。</p>
<p>TensorFlow Lite 转换器提供两种转换方法：</p>
<ul>
<li>Python API：它让您可以更轻松地在模型开发流水线中转换模型、应用优化、添加元数据，并且拥有更多功能</li>
<li>命令行：它仅支持基本模型转换</li>
</ul>
<p>将 SavedModel 转换为 TensorFlow Lite 模型，官方给提供了两种方式的实例代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the model</span></span><br><span class="line"><span class="comment"># TensorFlow 1.x</span></span><br><span class="line">converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(saved_model_dir) <span class="comment"># path to the SavedModel directory</span></span><br><span class="line"><span class="comment"># TensorFlow 2.x</span></span><br><span class="line"><span class="comment"># converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) </span></span><br><span class="line">tflite_model = converter.convert()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Save the model.</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;model.tflite&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">  f.write(tflite_model)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tflite_convert \</span><br><span class="line">  --saved_model_dir=/tmp/mobilenet_saved_model \</span><br><span class="line">  --output_file=/tmp/mobilenet.tflite</span><br></pre></td></tr></table></figure>

<p>示例代码中的 <code>saved_model_dir</code> 和 <code>mobilenet_saved_model</code> 路径一定要写对，正确的是上面训练好的模型 <code>model/saved_model</code> ，不要只写到 <code>model</code> ，否则会报下面错误。</p>
<blockquote>
<p>OSError: SavedModel file does not exist at: object_detection/ssd_model/model/{saved_model.pbtxt|saved_model.pb}</p>
</blockquote>
<p>当你开始转换，看着终端不断输出，然后它就又会报错了。</p>
<blockquote>
<p>ValueError: None is only supported in the 1st dimension. Tensor ‘image_tensor’ has invalid shape ‘[None, None, None, 3]’.</p>
</blockquote>
<h2 id="开始转换"><a href="#开始转换" class="headerlink" title="开始转换"></a>开始转换</h2><p>从我们上面训练好的模型转换成 tflite 只需要两步：</p>
<ol>
<li><p>先把 model.ckpt 转成 pb 和 pbtxt 文件，用的是 <code>object_detection/export_tflite_ssd_graph.py</code>，可以参考 <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/blob/master/research/object_detection/export_tflite_ssd_graph.py">export_tflite_ssd_graph.py</a>，下面是示例代码。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd models/research/</span></span><br><span class="line">python object_detection/export_tflite_ssd_graph.py \</span><br><span class="line">  --pipeline_config_path path\to\ssd_model\model\pipeline.config \</span><br><span class="line">  --trained_checkpoint_prefix path\to\ssd_model\model\model.ckpt \</span><br><span class="line">  --output_directory path\to\ssd_model\model</span><br><span class="line">  </span><br><span class="line"><span class="comment"># pipeline_config_path pipeline 配置文件位置</span></span><br><span class="line"><span class="comment"># trained_checkpoint_prefix ckpt 文件位置</span></span><br><span class="line"><span class="comment"># output_directory 导出 pb 文件位置</span></span><br></pre></td></tr></table></figure>

<p>此时在 <code>ssd_model\model</code> 下会生成两个文件：<code>tflite_graph.pb</code> 和 <code>tflite_graph.pbtxt</code></p>
</li>
<li><p>接下来把 pb 转为 tflite 文件，官方给的示例代码总是报错原因就在这，我们少了第一步，直接转换了 <code>saved_model.pb</code> 到 <code>tflite</code>，同时也缺少模型转换参数，下面是示例代码。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">tflite_convert \</span><br><span class="line">  --graph_def_file=path\to\ssd_model\model\tflite_graph.pb \</span><br><span class="line">  --output_file=path\to\ssd_model\model\ssd_mobilenet.tflite \</span><br><span class="line">  --input_arrays=normalized_input_image_tensor \</span><br><span class="line">  --output_arrays=<span class="string">&#x27;TFLite_Detection_PostProcess&#x27;</span>,<span class="string">&#x27;TFLite_Detection_PostProcess:1&#x27;</span>,<span class="string">&#x27;TFLite_Detection_PostProcess:2&#x27;</span>,<span class="string">&#x27;TFLite_Detection_PostProcess:3&#x27;</span> \</span><br><span class="line">  --input_shape=1,300,300,3 \</span><br><span class="line">  --allow_custom_ops</span><br><span class="line"></span><br><span class="line"><span class="comment"># graph_def_file 第一步中 tflite_graph.pb路径</span></span><br><span class="line"><span class="comment"># output_file tflite 导出路径</span></span><br><span class="line"><span class="comment"># input_shape 1,x,x,1 根据配置文件修改</span></span><br></pre></td></tr></table></figure>

<p>至此我们完成了 tflite 模型转换。</p>
<p>可以在嵌入式、移动端部署了，下图是使用的  ssd_mobilenet_v1_coco.tflite 模型在树莓派部署效果图。推断时间大概在 400-500 ms，实时性不是很好，使用最新的 ssd_mobilenet_v3_small 速度大约提高了一倍，ssd_mobilenet_v3_large 推断时间比 v1 略高100ms，但是准确率有很大的提升，大厂的产品不得不服啊！<img src="ssd_mobilenet_v1.jpg"></p>
</li>
</ol>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a target="_blank" rel="noopener" href="http://wossoneri.github.io/2017/12/12/%5BTensorflow%5DTrain-model-with-SSD-MobileNet/#toc-heading-1">[Tensorflow] 使用SSD-MobileNet训练模型</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/20f7f3755ddd">MobileNet SSD V2模型的压缩与tflite格式的转换（补充版）</a></p>
<p><a target="_blank" rel="noopener" href="https://www.tensorflow.org/lite/convert/index?hl=zh-cn">TensorFlow Lite 转换器</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/630c27cb8c55?utm_campaign=haruki">30组-MobileNets论文解读和MobileNetV2简介</a></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">gzwang</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://gzwangu.github.io/2021/03/27/MobileNet-SSD模型的训练与tflite格式转换/">https://gzwangu.github.io/2021/03/27/MobileNet-SSD模型的训练与tflite格式转换/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://gzwangu.github.io">Rubina の blog</a>！</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CNN/">CNN</a><a class="post-meta__tags" href="/tags/MobileNet-SSD/">MobileNet-SSD</a><a class="post-meta__tags" href="/tags/tensorflow-lite/">tensorflow lite</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2021/03/30/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F%E5%92%8C%E8%AE%A1%E7%AE%97%E9%87%8F/"><i class="fa fa-chevron-left">  </i><span>卷积神经网络中的参数量和计算量</span></a></div><div class="next-post pull-right"><a href="/2021/03/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"><span>机器学习基础知识</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2020 - 2022 By gzwang</div><div class="framework-info"><span>驱动 - </span><a target="_blank" rel="noopener" href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 - </span><a target="_blank" rel="noopener" href="https://github.com/Molunerfinn/hexo-theme-melody"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.9.0"></script><script src="/js/fancybox.js?version=1.9.0"></script><script src="/js/sidebar.js?version=1.9.0"></script><script src="/js/copy.js?version=1.9.0"></script><script src="/js/fireworks.js?version=1.9.0"></script><script src="/js/transition.js?version=1.9.0"></script><script src="/js/scroll.js?version=1.9.0"></script><script src="/js/head.js?version=1.9.0"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|iPad|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
  $('#top-container').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a target="_blank" rel="noopener" href="https://github.com/wzpan/hexo-generator-search" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>